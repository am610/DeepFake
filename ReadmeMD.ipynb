{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Skyhawk\n",
    "\n",
    "The goal of this proect is to build a pipeline for detecting whether a  given video, is a real or fake video. \n",
    "\n",
    "\n",
    "## Deep Fakes Detection\n",
    "This repository contains the souce code for classifying videos whether they are Deepfakes or not. Deepfake algorithms can create fake images and videos that humans can't detect from the authentic one. Generation of Deepfakes has begun to erode people's trust in media and question on their reliability and unbiasedness. Therefore the accurate identification of Deepfake videos via the establishement of robust pipeline is going to be necessary at present. \n",
    "\n",
    " Deep learning algorithms in recent years have been comprehensively used to solve various complex problems. It is also showing promising results in terms of Deepfake detection.  Various established deep learning based architectures are successfully used for Deepfake detections as well as coninuous ongoing researches are developing better algorithms.  \n",
    "\n",
    " \n",
    "\n",
    "## Algorithm\n",
    "Our algorithm for Deepfake detection is a deep convolutional network based on the state of the art    <a href=\"https://arxiv.org/pdf/1602.07261.pdf\">$Inception$ $Resnet$ $V2$</a> architecture.    This stems from the family of Inception deep convolutional architecture originally called as the <a href=\"https://arxiv.org/abs/1409.4842\">GoogLeNet</a>.  Res Net : Residual Network with Stochastic Gradient Descent. It is trained on more than a million images from the ImageNet database. The network is $164$ layers deep with  $56$ùëÄ  parameters and can classify images into $1000$ object categories. As a result, the network has learned rich feature representations for a wide range of images. We use pretrained 'imagenet' for weights initialization while keeping the training option on i.e. $trainable=True$. \n",
    "\n",
    "Our classification is based on frame by frames approach from a given video. We train our neural network on the frames from the videos labelled as 'fake' and 'real' and then generate a model which can be used to identify new videos as fake or real. \n",
    "We used $open\\ CV2$ for extracting frames from the videos and then used the $dlib$ library to detect faces in them. \n",
    "\n",
    "## Data Set\n",
    "\n",
    "\n",
    "To train our classifier, we made use of '.mp4' videos, seperated into binary labels : [Fake, Real]. There were $200$ videos of each label.  Length of videos vary roughly between few seconds to $2$ minutes and file sizes on an averge are $<20 MB$ but  files as big as $110 MB$ were also used.  \n",
    "\n",
    "##  Hyperparameters   \n",
    "Pooling      : Global Average Pooling<br>\n",
    "Acitvation : Softmax<br>\n",
    "Optimizer : Adam<br>\n",
    "Batch Size : $80$<br>\n",
    "Accuracy   : $99.7\\%(\\sim 3 \\sigma)$ for Training to terminate \n",
    "\n",
    "## Performance\n",
    "\n",
    " Accuracy $\\%$ = $98.5 (\\sim 2.96\\sigma)$<br>\n",
    "True positive $= 11157 , (51.87)\\%$ <br>\n",
    "False positive = $192 , (0.89)\\%$ <br>\n",
    "False negative = $130 , (0.60)\\%$ <br>\n",
    "True negative = $10031 , (46.63)\\%$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"Confusion.png\" width=\"400\" />\n",
    "\n",
    "<br>\n",
    "\n",
    "The accuracy and Loss of the train and test sets are plotted below. \n",
    "<img src=\"Loss2.png\" width=\"1000\" />\n",
    "\n",
    "<br>\n",
    "We see that there is a tendency for the validation set to ovefit as can be seen from the Loss function plot. We speculate further future improvement on the model can be made, by fine tunning the hyperparameters. This includes attention to reducing the overfitting tendency (though this is not highly pronounced, but can be improved). Adding suitable 'dropout' layer could assist in this condition, aditionally the learning rate of the 'Adam' optimizer can be further scrutinized by adding decay parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
